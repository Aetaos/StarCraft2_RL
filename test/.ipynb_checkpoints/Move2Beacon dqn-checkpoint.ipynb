{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.lib import actions\n",
    "from pysc2.lib import features\n",
    "from pysc2.env import sc2_env, run_loop, available_actions_printer\n",
    "from pysc2 import maps\n",
    "from absl import flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D,Dropout,Flatten,Activation,MaxPool1D,MaxPool2D\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the flags for the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_AI_RELATIVE = features.SCREEN_FEATURES.player_relative.index\n",
    "_AI_SELECTED = features.SCREEN_FEATURES.selected.index\n",
    "_NO_OP = actions.FUNCTIONS.no_op.id\n",
    "_MOVE_SCREEN = actions.FUNCTIONS.Attack_screen.id\n",
    "_SELECT_ARMY = actions.FUNCTIONS.select_army.id\n",
    "_SELECT_POINT = actions.FUNCTIONS.select_point.id\n",
    "_MOVE_RAND = 1000\n",
    "_MOVE_MIDDLE = 2000\n",
    "_BACKGROUND = 0\n",
    "_AI_SELF = 1\n",
    "_AI_ALLIES = 2\n",
    "_AI_NEUTRAL = 3\n",
    "_AI_HOSTILE = 4\n",
    "_SELECT_ALL = [0]\n",
    "_NOT_QUEUED = [0]\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.025\n",
    "EPS_DECAY = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define our actions\n",
    "# it can choose to move to\n",
    "# the beacon or to do nothing\n",
    "# it can select the marine or deselect\n",
    "# the marine, it can move to a random point\n",
    "possible_actions = [\n",
    "    _NO_OP,\n",
    "    _SELECT_ARMY,\n",
    "    _SELECT_POINT,\n",
    "    _MOVE_SCREEN,\n",
    "    _MOVE_RAND,\n",
    "    _MOVE_MIDDLE\n",
    "]\n",
    "id_from_actions={}\n",
    "for ix,k in enumerate(possible_actions):\n",
    "    id_from_actions[k]=ix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_state(obs):\n",
    "    ai_view = obs.observation['feature_screen'][_AI_RELATIVE]\n",
    "    beaconxs, beaconys = (ai_view == _AI_NEUTRAL).nonzero()\n",
    "    marinexs, marineys = (ai_view == _AI_SELF).nonzero()\n",
    "    marinex, mariney = marinexs.mean(), marineys.mean()\n",
    "        \n",
    "    marine_on_beacon = np.min(beaconxs) <= marinex <=  np.max(beaconxs) and np.min(beaconys) <= mariney <=  np.max(beaconys)\n",
    "        \n",
    "    # get a 1 or 0 for whether or not our marine is selected\n",
    "    ai_selected = obs.observation['feature_screen'][_AI_SELECTED]\n",
    "    marine_selected = int((ai_selected == 1).any())\n",
    "    return [np.array([ai_view]),np.array([marine_selected])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 64, 64)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 57, 16)       8208        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 57, 16)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 28, 16)       0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 25, 32)       2080        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 32)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 6, 32)        0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 192)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 192)          0           flatten_1[0][0]                  \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 6)            1158        add_7[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 11,446\n",
      "Trainable params: 11,446\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = keras.layers.Input(shape=(64,64))\n",
    "model_view = Conv1D(16, kernel_size=(8,), input_shape=(64,64))(input1)\n",
    "model_view = Activation('relu')(model_view)\n",
    "model_view = MaxPool1D(pool_size=(2,), strides=(2,), padding='valid')(model_view)\n",
    "model_view = Conv1D(32, kernel_size=(4, ), input_shape=(64,64))(model_view)\n",
    "model_view = Activation('relu')(model_view)\n",
    "model_view = MaxPool1D(pool_size=(2, ), strides=(4,), padding='valid')(model_view)\n",
    "model_view=Flatten()(model_view)\n",
    "\n",
    "#model_view.compile()\n",
    "\n",
    "input2 = keras.layers.Input(shape=(1,))\n",
    "# equivalent to added = keras.layers.add([x1, x2])\n",
    "added = keras.layers.Add()([model_view, input2])\n",
    "\n",
    "out = keras.layers.Dense(len(possible_actions),activation='softmax')(added)\n",
    "model = keras.models.Model(inputs=[input1, input2], outputs=out)\n",
    "model.summary()\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPISODES = 500\n",
    "import random\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, model):\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = model\n",
    "\n",
    "   \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(possible_actions)\n",
    "        act_values = self.model.predict(state)\n",
    "        return possible_actions[np.argmax(act_values[0])]\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][id_from_actions[action]] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "FLAGS(['run_sc2'])\n",
    "\n",
    "viz = False\n",
    "save_replay = False\n",
    "steps_per_episode = 0 # 0 actually means unlimited\n",
    "MAX_EPISODES =35\n",
    "MAX_STEPS = 400\n",
    "steps = 0\n",
    "\n",
    "# create a map\n",
    "beacon_map = maps.get('MoveToBeacon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_action(id_action,feature_screen):\n",
    "    beacon_pos = (feature_screen == _AI_NEUTRAL).nonzero()\n",
    "\n",
    "    if id_action== _NO_OP:\n",
    "        func = actions.FunctionCall(_NO_OP, [])\n",
    "    elif id_action == _MOVE_SCREEN:\n",
    "        beacon_x, beacon_y = beacon_pos[0].mean(), beacon_pos[1].mean()\n",
    "        func = actions.FunctionCall(_MOVE_SCREEN, [_NOT_QUEUED, [beacon_y, beacon_x]])\n",
    "    elif id_action == _SELECT_ARMY:\n",
    "        func = actions.FunctionCall(_SELECT_ARMY, [_SELECT_ALL])\n",
    "    elif id_action == _SELECT_POINT:\n",
    "        backgroundxs, backgroundys = (feature_screen == _BACKGROUND).nonzero()\n",
    "        point = np.random.randint(0, len(backgroundxs))\n",
    "        backgroundx, backgroundy = backgroundxs[point], backgroundys[point]\n",
    "        func = actions.FunctionCall(_SELECT_POINT, [_NOT_QUEUED, [backgroundy, backgroundx]])\n",
    "    elif id_action == _MOVE_RAND:\n",
    "        beacon_x, beacon_y = beacon_pos[0].max(), beacon_pos[1].max()\n",
    "        movex, movey = np.random.randint(beacon_x, 64), np.random.randint(beacon_y, 64)\n",
    "        func = actions.FunctionCall(_MOVE_SCREEN, [_NOT_QUEUED, [movey, movex]])\n",
    "    elif id_action == _MOVE_MIDDLE:\n",
    "        func = actions.FunctionCall(_MOVE_SCREEN, [_NOT_QUEUED, [32, 32]])\n",
    "    return func\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sc2_env.SC2Env(agent_race=None,\n",
    "                    bot_race=None,\n",
    "                    difficulty=None,\n",
    "                    map_name=beacon_map,\n",
    "                    visualize=viz,agent_interface_format=sc2_env.AgentInterfaceFormat(\n",
    "              feature_dimensions=sc2_env.Dimensions(\n",
    "                  screen=64,\n",
    "                  minimap=64))) as env :\n",
    "    agent = DQNAgent(model)\n",
    "    #agent.load(\"./save/move_2_beacon-dqn.h5\")\n",
    "    \n",
    "    done = False\n",
    "    batch_size = 32\n",
    "    \n",
    "    for e in range(EPISODES):\n",
    "        obs = env.reset()\n",
    "        score=0\n",
    "        state = get_state(obs[0])\n",
    "        for time in range(500):\n",
    "            # env.render()\n",
    "            a=agent.act(state)\n",
    "            if not a in obs[0].observation.available_actions:\n",
    "                a=_NO_OP\n",
    "            func=get_action(a,state[0][0])\n",
    "            next_obs=env.step([func])\n",
    "            next_state = get_state(next_obs[0])\n",
    "            reward = next_obs[0].reward\n",
    "            score+= reward\n",
    "            done=next_obs[0].last()\n",
    "            agent.remember(state, a, reward, next_state, done)\n",
    "            state = next_state\n",
    "            obs=next_obs\n",
    "            if done:\n",
    "                print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                      .format(e, EPISODES, score, agent.epsilon))\n",
    "                break\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "        agent.save(\"./save/move_2_beacon-dqn.h5\")\n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
