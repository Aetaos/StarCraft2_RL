{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from pysc2.agents import base_agent\n",
    "from pysc2.lib import actions\n",
    "from pysc2.lib import features\n",
    "from pysc2.env import sc2_env, run_loop, available_actions_printer\n",
    "from pysc2 import maps\n",
    "from absl import flags\n",
    "from collections import deque\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D,Dropout,Flatten,Activation,MaxPool1D,MaxPool2D\n",
    "from keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_AI_RELATIVE = features.SCREEN_FEATURES.player_relative.index\n",
    "_AI_SELECTED = features.SCREEN_FEATURES.selected.index\n",
    "_NO_OP = actions.FUNCTIONS.no_op.id\n",
    "_MOVE_SCREEN = actions.FUNCTIONS.Attack_screen.id\n",
    "_SELECT_ARMY = actions.FUNCTIONS.select_army.id\n",
    "_SELECT_POINT = actions.FUNCTIONS.select_point.id\n",
    "_MOVE_RAND = 1000\n",
    "_MOVE_MIDDLE = 2000\n",
    "_BACKGROUND = 0\n",
    "_AI_SELF = 1\n",
    "_AI_ALLIES = 2\n",
    "_AI_NEUTRAL = 3\n",
    "_AI_HOSTILE = 4\n",
    "_SELECT_ALL = [0]\n",
    "_NOT_QUEUED = [0]\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.025\n",
    "EPS_DECAY = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our actions\n",
    "# it can choose to move to\n",
    "# the beacon or to do nothing\n",
    "# it can select the marine or deselect\n",
    "# the marine, it can move to a random point\n",
    "possible_actions = [\n",
    "    _NO_OP,\n",
    "    _SELECT_ARMY,\n",
    "    _SELECT_POINT,\n",
    "    _MOVE_SCREEN,\n",
    "    _MOVE_RAND,\n",
    "    _MOVE_MIDDLE\n",
    "]\n",
    "id_from_actions={}\n",
    "for ix,k in enumerate(possible_actions):\n",
    "    id_from_actions[k]=ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(obs):\n",
    "    ai_view = obs.observation['feature_screen'][_AI_RELATIVE]\n",
    "    beaconxs, beaconys = (ai_view == _AI_NEUTRAL).nonzero()\n",
    "    marinexs, marineys = (ai_view == _AI_SELF).nonzero()\n",
    "    marinex, mariney = marinexs.mean(), marineys.mean()\n",
    "        \n",
    "    marine_on_beacon = np.min(beaconxs) <= marinex <=  np.max(beaconxs) and np.min(beaconys) <= mariney <=  np.max(beaconys)\n",
    "        \n",
    "    # get a 1 or 0 for whether or not our marine is selected\n",
    "    ai_selected = obs.observation['feature_screen'][_AI_SELECTED]\n",
    "    marine_selected = int((ai_selected == 1).any())\n",
    "    return [np.array([ai_view]),np.array([marine_selected])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fullyconv LSTM agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 64, 64)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 64, 64)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 60, 16)       5136        input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 60, 16)       5136        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 60, 16)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 60, 16)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 30, 16)       0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 30, 16)       0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 28, 32)       1568        max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 28, 32)       1568        max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 32)       0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 32)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 14, 32)       0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 14, 32)       0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 448)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 448)          0           max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 897)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          229888      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            257         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 6)            1542        dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 245,095\n",
      "Trainable params: 245,095\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#map conv\n",
    "input_map = keras.layers.Input(shape=(64,64))\n",
    "\n",
    "model_view_map = Conv1D(16, kernel_size=(5,), input_shape=(64,64))(input_map)\n",
    "model_view_map = Activation('relu')(model_view_map)\n",
    "model_view_map = MaxPool1D(pool_size=(2,), strides=None, padding='valid')(model_view_map)\n",
    "model_view_map = Conv1D(32, kernel_size=(3, ), input_shape=(64,64))(model_view_map)\n",
    "model_view_map = Activation('relu')(model_view_map)\n",
    "model_view_map = MaxPool1D(pool_size=(2, ), strides=None, padding='valid')(model_view_map)\n",
    "model_view_map=Flatten()(model_view_map)\n",
    "\n",
    "#minimap conv\n",
    "input_mini = keras.layers.Input(shape=(64,64))\n",
    "model_view_mini = Conv1D(16, kernel_size=(5,), input_shape=(64,64))(input_mini)\n",
    "model_view_mini = Activation('relu')(model_view_mini)\n",
    "model_view_mini = MaxPool1D(pool_size=(2,), strides=None, padding='valid')(model_view_mini)\n",
    "model_view_mini = Conv1D(32, kernel_size=(3, ), input_shape=(64,64))(model_view_mini)\n",
    "model_view_mini = Activation('relu')(model_view_mini)\n",
    "model_view_mini = MaxPool1D(pool_size=(2, ), strides=None, padding='valid')(model_view_mini)\n",
    "model_view_mini=Flatten()(model_view_mini)\n",
    "\n",
    "\n",
    "#model_view.compile()\n",
    "\n",
    "input_feat = keras.layers.Input(shape=(1,))\n",
    "# equivalent to added = keras.layers.add([x1, x2])\n",
    "\n",
    "#concatenate\n",
    "added = keras.layers.concatenate([model_view_map, model_view_mini, input_feat])\n",
    "\n",
    "#LSTM\n",
    "\n",
    "\n",
    "intermediate = keras.layers.Dense(256,activation='relu')(added)\n",
    "#intermediate = Flatten()(intermediate)\n",
    "out_value = keras.layers.Dense(1,activation='relu')(intermediate)\n",
    "out_non_spatial = keras.layers.Dense(len(possible_actions), activation='relu')(intermediate)\n",
    "model = keras.models.Model(inputs=[input_map, input_mini, input_feat], outputs=[out_value, out_non_spatial])\n",
    "model.summary()\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 500\n",
    "import random\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, model):\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = model\n",
    "\n",
    "   \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(possible_actions)\n",
    "        act_values, act_non_spatial = self.model.predict(state)\n",
    "        return possible_actions[np.argmax(act_non_spatial[0])]\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][id_from_actions[action]] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "FLAGS(['run_sc2'])\n",
    "\n",
    "viz = True\n",
    "save_replay = False\n",
    "steps_per_episode = 0 # 0 actually means unlimited\n",
    "MAX_EPISODES =100\n",
    "MAX_STEPS = 400\n",
    "steps = 0\n",
    "\n",
    "# create a map\n",
    "beacon_map = maps.get('MoveToBeacon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(id_action,feature_screen):\n",
    "    beacon_pos = (feature_screen == _AI_NEUTRAL).nonzero()\n",
    "\n",
    "    if id_action== _NO_OP:\n",
    "        func = actions.FunctionCall(_NO_OP, [])\n",
    "    elif id_action == _MOVE_SCREEN:\n",
    "        beacon_x, beacon_y = beacon_pos[0].mean(), beacon_pos[1].mean()\n",
    "        func = actions.FunctionCall(_MOVE_SCREEN, [_NOT_QUEUED, [beacon_y, beacon_x]])\n",
    "    elif id_action == _SELECT_ARMY:\n",
    "        func = actions.FunctionCall(_SELECT_ARMY, [_SELECT_ALL])\n",
    "    elif id_action == _SELECT_POINT:\n",
    "        backgroundxs, backgroundys = (feature_screen == _BACKGROUND).nonzero()\n",
    "        point = np.random.randint(0, len(backgroundxs))\n",
    "        backgroundx, backgroundy = backgroundxs[point], backgroundys[point]\n",
    "        func = actions.FunctionCall(_SELECT_POINT, [_NOT_QUEUED, [backgroundy, backgroundx]])\n",
    "    elif id_action == _MOVE_RAND:\n",
    "        beacon_x, beacon_y = beacon_pos[0].max(), beacon_pos[1].max()\n",
    "        movex, movey = np.random.randint(beacon_x, 64), np.random.randint(beacon_y, 64)\n",
    "        func = actions.FunctionCall(_MOVE_SCREEN, [_NOT_QUEUED, [movey, movex]])\n",
    "    elif id_action == _MOVE_MIDDLE:\n",
    "        func = actions.FunctionCall(_MOVE_SCREEN, [_NOT_QUEUED, [32, 32]])\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sc2_env.SC2Env(agent_race=None,\n",
    "                    bot_race=None,\n",
    "                    difficulty=None,\n",
    "                    map_name=beacon_map,\n",
    "                    visualize=viz,agent_interface_format=sc2_env.AgentInterfaceFormat(\n",
    "              feature_dimensions=sc2_env.Dimensions(\n",
    "                  screen=64,\n",
    "                  minimap=64))) as env :\n",
    "    agent = DQNAgent(model)\n",
    "    #agent.load(\"./save/move_2_beacon-dqn.h5\")\n",
    "    \n",
    "    done = False\n",
    "    batch_size = 32\n",
    "    \n",
    "    for e in range(EPISODES):\n",
    "        obs = env.reset()\n",
    "        score=0\n",
    "        state = get_state(obs[0])\n",
    "        for time in range(500):\n",
    "            # env.render()\n",
    "            a=agent.act(state)\n",
    "            if not a in obs[0].observation.available_actions:\n",
    "                a=_NO_OP\n",
    "            func=get_action(a,state[0][0])\n",
    "            next_obs=env.step([func])\n",
    "            next_state = get_state(next_obs[0])\n",
    "            reward = next_obs[0].reward\n",
    "            score+= reward\n",
    "            done=next_obs[0].last()\n",
    "            agent.remember(state, a, reward, next_state, done)\n",
    "            state = next_state\n",
    "            obs=next_obs\n",
    "            if done:\n",
    "                print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                      .format(e, EPISODES, score, agent.epsilon))\n",
    "                break\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "        agent.save(\"./save/move_2_beacon-dqn.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
